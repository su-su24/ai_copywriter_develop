import streamlit as st
from openai import OpenAI

client = OpenAI(
    api_key = st.secrets["OPEN_API_KEY"]
)

st.title("ğŸ§‘â€ğŸ« ì‹­ëŒ€ë‘ ëŒ€í™”í•˜ëŠ” ê±° ì‰½ëŒ€")
st.subheader("í• ì•„ë²„ì§€! ì œê°€ ì•Œë ¤ë“œë¦´ê²Œìš”ğŸ£")

auto_complete = st.toggle(label="ì˜ˆì‹œë¡œ ì±„ìš°ê¸°")
example = {
    "name" : "ìº˜ë°•"
}

def generate_prompt(m_z_lan):
    system_message = f"""
ì•„ë˜ ì‹ ì¡°ì–´ ì‚¬ì „ì„ ì°¸ê³ í•´ì„œ ìœ ì €ì—ê²Œ ì‹ ì¡°ì–´ì˜ ì˜ë¯¸ë¥¼ ì•Œë ¤ì£¼ì„¸ìš”.
ì•„ì´ê°€ í• ì•„ë²„ì§€ì—ê²Œ ì„¤ëª…í•˜ëŠ” ì–´íˆ¬ë¡œ ì„¤ëª…í•´ì£¼ì„¸ìš”.
ì¬ë°ŒëŠ” ì˜ˆì‹œë„ ì´ëª¨ì§€ë¥¼ ì ì ˆíˆ ì„ì–´ì„œ 2ê°œ ì œì‹œí•´ì£¼ì„¸ìš”.
ë§Œì•½ ì œì‹œëœ ì‹ ì¡°ì–´ê°€ ì•„ë‹ˆë¼ë©´, ì •ì¤‘íˆ í‹€ë ¸ìŒì„ ëª…ì‹œí•´ì£¼ì„¸ìš”.

ìº˜ë°•: ìº˜ë¦°ë” ë°•ì œì˜ ì˜ë¯¸ë¡œ ì¼ì •ì„ í™•ì •í•œë‹¤ëŠ” ëœ»
ìŠ¤ë¶ˆì¬: ìŠ¤ìŠ¤ë¡œ ë¶ˆëŸ¬ì˜¨ ì¬ì•™ì˜ ì¤„ì„ë§ë¡œ ë„ˆë¬´ ë§ì€ ìš•ì‹¬ì„ ë¶€ë ¤ì„œ ìŠ¤ìŠ¤ë¡œë¥¼ ê³ í†µìŠ¤ëŸ½ê²Œ í•˜ëŠ” ì‚¬ëŒì„ ì´ë¦„
í¸ë””ì¡±: í¸ì˜ì  ë””ì €íŠ¸ë¥¼ ì¦ê¸°ëŠ” ì‚¬ëŒì„ ì´ë¦„
ì¹´ê³µì¡±: ì¹´í˜ë¥¼ í•™ìŠµê³µê°„ìœ¼ë¡œ ì‚¬ìš©í•˜ëŠ” ì‚¬ëŒì„ ì´ë¦„
í¼ ë¯¸ì³¤ë‹¤: ê¸°ëŸ‰ì´ ë§¤ìš° ë›°ì–´ë‚˜ë‹¤ëŠ” ëœ»
ì¢‹ëŒ“êµ¬ì•Œ: ì¢‹ì•„ìš”, ëŒ“ê¸€, êµ¬ë…, ì•Œë¦¼ì„¤ì •ì˜ ì¤„ì„ë§
ì¼ë©°ë“¤ë‹¤: ì¼ì´ ë‚´ ì‚¶ì— ìŠ¤ë©°ë“¤ì—ˆë‹¤ëŠ” ëœ»
ì¤‘êº¾ë§ˆ: ì¤‘ìš”í•œ ê±´ êº¾ì´ì§€ ì•ŠëŠ” ë§ˆìŒì˜ ì¤„ì„ë§
ì‹«ì¡´ì£¼ì˜: ì‹«ì–´í•˜ëŠ” ê²ƒì„ ì¡´ì¤‘í•˜ìëŠ” ì£¼ì˜
ê°“ìƒ: God(ê°“)+ì¸ìƒ, ì„±ì‹¤í•˜ê³  ë¶€ì§€ëŸ°í•˜ì—¬ ì„±ê³µí•œ ì‚¶
ë¼ì§€ëŸ°í•˜ë‹¤: í‰ì†Œì—ëŠ” ê²Œìœ¼ë¥¸ë° ë¨¹ì„ ë•Œë§Œ ë¶€ì§€ëŸ°í•˜ë‹¤ëŠ” ì˜ë¯¸
ì €ë©”ì¶”: ì €ë… ë©”ë‰´ ì¶”ì²œ ì¤„ì„ë§
ì‚¬ë°”ì‚¬: ì‚¬ëŒ ë°”ì´ ì‚¬ëŒ ì¤„ì„ë§, ì‚¬ëŒì— ë”°ë¼ ë‹¤ë¥´ë‹¤ëŠ” ì˜ë¯¸
ì¼€ë°”ì¼€: ì¼€ì´ìŠ¤ ë°”ì´ ì¼€ì´ìŠ¤ ì¤„ì„ë§, ìƒí™©ì— ë”°ë¼ ë‹¤ë¥´ë‹¤ëŠ” ì˜ë¯¸
ê¾¸ì•ˆê¾¸: ê¾¸ë¯¼ë“¯ ì•ˆ ê¾¸ë¯¼ë“¯ ì¤„ì„ë§, ìˆ˜ìˆ˜í•˜ê²Œ ì´ì˜ë‹¤ëŠ” ê²ƒì„ ì˜ë¯¸
ê·¸ì¡ì±„: ê·¸ ìì²´ 
ê¾¸ì›¨ì—‘: í›„íšŒí•´
ë”í™©ì± : ë„ë§ì³
ì–µí…: ì–µì§€ í…ì…˜ì„ ëœ»í•¨
ìë‚³ê´´: ìë³¸ì£¼ì˜ê°€ ë‚³ì€ ê´´ë¬¼ì´ë¼ê³  ì •ì´ ì—†ê³  ëˆì„ ì¶”êµ¬í•˜ëŠ” ì‚¬ëŒì„ ì´ë¦„
---
ì‹ ì¡°ì–´:{m_z_lan}
---
    """.strip()
    return system_message

def request_chat_completion(system_message):
    response = client.chat.completions.create(
        model="gpt-4-1106-preview",
        messages=[
            {"role": "system", "content": system_message},
            {"role": "user", "content": f"{name}ì€ ë¬´ìŠ¨ ëœ»ì´ì•¼?"}
        ],
        stream=True
    )
    return response

def print_streaming_response(response):
    message = ""
    placeholder = st.empty()
    for chunk in response:
        delta = chunk.choices[0].delta
        if delta.content:
            message += delta.content
            placeholder.markdown(message + "â–Œ")
    placeholder.markdown(message)

with st.form("form"):
    name = st.text_input(
        "ì•Œê³  ì‹¶ì€ ì‹ ì¡°ì–´(í•„ìˆ˜)",
        value=example["name"] if auto_complete else "",
        placeholder=example["name"])
    submit = st.form_submit_button("ì œì¶œí•˜ê¸°")
if submit:
    if not name:
        st.error("ì•Œê³  ì‹¶ì€ ì‹ ì¡°ì–´ë¥¼ ì…ë ¥í•´ ì£¼ì„¸ìš”.")
    else:
        system_message = generate_prompt(
            m_z_lan=name)
        response = request_chat_completion(system_message)
        print_streaming_response(response)